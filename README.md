# ğŸ³ **Dockerisation Layer â€” LLMOps Medical Chatbot**

This branch introduces **Docker containerisation** for the LLMOps Medical Chatbot.
It packages the entire Flask application, RAG pipeline, and supporting modules into a lightweight Python 3.12 container, enabling consistent deployment across all environments including local development, servers, and Kubernetes.

By completing this step, the chatbot is now fully portable and can run anywhere Docker is supported.

## ğŸ—‚ï¸ **Project Structure (Updated)**

```text
LLMOPS-MEDICAL-CHATBOT/
â”œâ”€â”€ Dockerfile                 # NEW: Fully documented Python 3.12 Dockerfile
â”œâ”€â”€ .venv/
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ setup.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ The_GALE_ENCYCLOPEDIA_OF_MEDICINE_SECOND.pdf
â””â”€â”€ app/
    â”œâ”€â”€ application.py
    â”‚
    â”œâ”€â”€ common/
    â”‚   â”œâ”€â”€ custom_exception.py
    â”‚   â””â”€â”€ logger.py
    â”‚
    â”œâ”€â”€ config/
    â”‚   â””â”€â”€ config.py
    â”‚
    â”œâ”€â”€ components/
    â”‚   â”œâ”€â”€ pdf_loader.py
    â”‚   â”œâ”€â”€ embeddings.py
    â”‚   â”œâ”€â”€ vector_store.py
    â”‚   â”œâ”€â”€ data_loader.py
    â”‚   â”œâ”€â”€ llm.py
    â”‚   â””â”€â”€ retriever.py
    â”‚
    â”œâ”€â”€ templates/
    â”‚   â””â”€â”€ index.html
    â”‚
    â””â”€â”€ static/
        â””â”€â”€ style.css
```

## âš™ï¸ **What Was Implemented in This Branch**

### ğŸ 1. Switched Base Image to `python:3.12-slim`

The project now uses a lightweight, secure Python 3.12 environment.
The base image was updated from 3.10 to 3.12 to match your current local environment and to ensure long-term support.

### âš¡ 2. Added Full Dockerfile With Documentation

A fully documented production-ready Dockerfile was created featuring:

* Python 3.12-slim parent image
* Disabled `.pyc` bytecode generation
* Unbuffered Python output for clean logs
* Build tools installation (`build-essential`, `curl`)
* Project copied into `/app`
* `pip install -e .` for editable installs
* Port 5000 exposed for Flask
* Launch command:

  ```
  CMD ["python", "app/application.py"]
  ```

All instructions follow best practices and include concise inline comments and a NumPy-style header documentation block.

### ğŸ“¦ 3. Project Prepared for Containerised Execution

The entire application can now run inside Docker with a single command:

```
docker build -t medical-chatbot .
docker run -p 5000:5000 medical-chatbot
```

This ensures:

* Identical environments across development and deployment
* Isolation from system Python configurations
* Easy compatibility with CI/CD pipelines and platforms like Kubernetes

### ğŸ§¹ 4. Clean Build Context and Stable Layering

The Dockerfile minimises image layers, cleans up APT cache, and avoids storing pip cache to keep the container small and efficient.

## ğŸ§ª **Dockerisation Status**

The container builds correctly and runs the chatbot with full UI functionality:

* Flask app starts up normally
* RAG chain loads as expected
* Message history works
* Web UI is served on port 5000
* No bytecode or pip cache clutter in the image

The image is stable and suitable for use in later deployment branches.

## âœ… **Summary**

This branch introduces complete Docker support for the LLMOps Medical Chatbot:

* Fully documented Python 3.12 Dockerfile
* Portable, reproducible execution environment
* Works seamlessly with Flask, LangChain, embeddings, and vector store
* Prepares the project for CI/CD and deployment pipelines

The chatbot can now be run anywhere â€” locally, in the cloud, or inside Kubernetes â€” using a single container.